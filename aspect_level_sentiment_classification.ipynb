{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rhnfzl/2IMM10-DeepLearnig-Assignments/blob/master/Assignment%20III/Assignment-3.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5BoXrK_u3u_"
   },
   "source": [
    "# Assignment 4. Sequence Classification\n",
    "\n",
    "<b>Group [30]</b>\n",
    "* <b> Student </b> : Rehan Fazal + 1423002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sr9zwNA-u3vH"
   },
   "source": [
    "# Task: Aspect-level Sentiment Classification(10pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y506kXSAu3vP"
   },
   "source": [
    "Reading material:\n",
    "- [1] R. He, WS. Lee & D. Dahlmeier. Exploiting document knowledge for aspect-level sentiment classification. 2018. https://arxiv.org/abs/1806.04346.\n",
    "\n",
    "\n",
    "Build an attention-based aspect-level sentiment classification model with biLSTM. Your model shall include:\n",
    "\n",
    "- BiLSTM network that learns sentence representation from input sequences.\n",
    "- Attention network that assigns attention score over a sequence of biLSTM hidden states based on aspect terms representation.\n",
    "- Fully connected network that predicts sentiment label, given the representation weighted by the attention score.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- You shall train your model bsaed on transferring learning. That is, you need first train your model on documnet-level examples. Then the learned weights will be used to initialize aspect-level model and fine tune it on aspect-level examples.\n",
    "- You shall use the alignment score function in attention network as following expression:$$f_{score}(h,t)=tanh(h^TW_a t)$$\n",
    "- You shall evaluate the trained model on the provided test set and show the accuracy on test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "FB6yxc4BM9uU",
    "outputId": "5973ef29-1248-4974-c7d9-729067c0e378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPDMoaQNNAC5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymEccUbRNEGd"
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9TH6Um2s-7d"
   },
   "source": [
    "\n",
    "#Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbWy_h2KtNgR"
   },
   "outputs": [],
   "source": [
    "def read_pickle(data_path, file_name):\n",
    "\n",
    "    f = open(os.path.join(data_path, file_name), 'rb')\n",
    "    read_file = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return read_file\n",
    "\n",
    "def save_pickle(data_path, file_name, data):\n",
    "\n",
    "    f = open(os.path.join(data_path, file_name), 'wb')\n",
    "    cPickle.dump(data, f)\n",
    "    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuAMxdYBkv_x"
   },
   "outputs": [],
   "source": [
    "aspect_path = '/drive/My Drive/Deep Learning Course/practice-5-data/aspect-level/'\n",
    "\n",
    "\n",
    "vocab = read_pickle(aspect_path, 'all_vocab.pkl')\n",
    "\n",
    "train_x = read_pickle(aspect_path, 'train_x.pkl')\n",
    "train_y = read_pickle(aspect_path, 'train_y.pkl')\n",
    "dev_x = read_pickle(aspect_path, 'dev_x.pkl')\n",
    "dev_y = read_pickle(aspect_path, 'dev_y.pkl')\n",
    "test_x = read_pickle(aspect_path, 'test_x.pkl')\n",
    "test_y = read_pickle(aspect_path, 'test_y.pkl')\n",
    "\n",
    "train_aspect = read_pickle(aspect_path, 'train_aspect.pkl')\n",
    "dev_aspect = read_pickle(aspect_path, 'dev_aspect.pkl')\n",
    "test_aspect = read_pickle(aspect_path, 'test_aspect.pkl')\n",
    "\n",
    "\n",
    "pretrain_data = read_pickle(aspect_path, 'pretrain_data.pkl')\n",
    "pretrain_label = read_pickle(aspect_path, 'pretrain_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWVgGO8RlVIJ"
   },
   "outputs": [],
   "source": [
    "class Dataiterator_doc():\n",
    "    '''\n",
    "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
    "      2) Access to the entire dataset using all()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y, seq_length=32, decoder_dim=300, batch_size=32):      \n",
    "        self.X = X \n",
    "        self.y = y \n",
    "        self.num_data = len(X) # total number of examples\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.reset() # initial: shuffling examples and set index to 0\n",
    "    \n",
    "    def __iter__(self): # iterates data\n",
    "        return self\n",
    "\n",
    "\n",
    "    def reset(self): # initials\n",
    "        self.idx = 0\n",
    "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
    "        \n",
    "    def __next__(self): # return model inputs - outputs per batch\n",
    "        X_ids = [] # hold ids per batch \n",
    "        while len(X_ids) < self.batch_size:\n",
    "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
    "            X_ids.append(X_id)\n",
    "            self.idx += 1 # \n",
    "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
    "                self.reset()\n",
    "                raise StopIteration()\n",
    "                \n",
    "        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n",
    "        batch_y = self.y[np.array(X_ids)] # y_in values (decoder input) per batch\n",
    "        return batch_X, batch_y\n",
    "\n",
    "          \n",
    "    def all(self): # return all data examples\n",
    "        return self.X, self.y\n",
    "class Dataiterator_aspect():\n",
    "    '''\n",
    "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
    "      2) Access to the entire dataset using all()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, aspect_data, seq_length=32, decoder_dim=300, batch_size=32):\n",
    "        \n",
    "        len_aspect_data = len(aspect_data[0])\n",
    "        #self.len_doc_data = len(doc_data[0])\n",
    "        \n",
    "        self.X_aspect = aspect_data[0] \n",
    "        self.y_aspect = aspect_data[1]\n",
    "        self.aspect_terms = aspect_data[2]  \n",
    "        self.num_data = len_aspect_data\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.reset() # initial: shuffling examples and set index to 0\n",
    "    \n",
    "    def __iter__(self): # iterates data\n",
    "        return self\n",
    "\n",
    "\n",
    "    def reset(self): # initials\n",
    "        self.idx = 0\n",
    "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
    "        \n",
    "    def __next__(self): # return model inputs - outputs per batch\n",
    "        \n",
    "        X_ids = [] # hold ids per batch \n",
    "        while len(X_ids) < self.batch_size:\n",
    "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
    "            X_ids.append(X_id)\n",
    "            self.idx += 1 # \n",
    "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
    "                self.reset()\n",
    "                raise StopIteration()\n",
    "                \n",
    "        batch_X_aspect = self.X_aspect[np.array(X_ids)] # X values (encoder input) per batch\n",
    "        batch_y_aspect = self.y_aspect[np.array(X_ids)] # y_in values (decoder input) per batch\n",
    "        batch_aspect_terms = self.aspect_terms[np.array(X_ids)]\n",
    "        \n",
    "        return batch_X_aspect, batch_y_aspect, batch_aspect_terms\n",
    "\n",
    "          \n",
    "    def all(self): # return all data examples\n",
    "        return self.X_aspect, self.y_aspect, self.aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38IEEx0du3vW",
    "outputId": "986f3416-4112-4425-e087-8bc2acb4c523"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, Lambda, Dropout, LSTM,Bidirectional\n",
    "from keras.layers import Reshape, Activation, RepeatVector, concatenate, Concatenate, Dot, Multiply\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cduHSpsSnVue"
   },
   "outputs": [],
   "source": [
    "overal_maxlen = 82\n",
    "overal_maxlen_aspect = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhTQke3HnvHN"
   },
   "source": [
    "\n",
    "#Define Attention Network Layer\n",
    "- Define class for Attention Layer\n",
    "- You need to finish the code for calculating the attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnDX-po3_50B"
   },
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self,  **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Content Attention mechanism.\n",
    "        Supports Masking.\n",
    "        \"\"\"\n",
    "       \n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert type(input_shape) == list\n",
    "       \n",
    "        self.steps = input_shape[0][1]\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[0][-1], input_shape[1][-1]),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),)\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input_tensor, mask=None):\n",
    "        assert type(input_tensor) == list\n",
    "        assert type(mask) == list\n",
    "        return None\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        x = input_tensor[0] #Output of BiLSTM of sentence\n",
    "        aspect = input_tensor[1] #Output of word embedding layer of aspect terms\n",
    "        mask = mask[0] #Used to remove the influence of padded value\n",
    "        ###YOUR CODE HERE###\n",
    "        #From the [1] git repo https://github.com/ruidan/Aspect-level-sentiment/blob/master/code/my_layers.py#L40\n",
    "        aspect = K.transpose(K.dot(self.W, K.transpose(aspect)))\n",
    "        aspect = K.expand_dims(aspect, axis=-2)\n",
    "        aspect = K.repeat_elements(aspect, self.steps, axis=1)\n",
    "        eij = K.sum(x*aspect, axis=-1)\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        return a\n",
    "\n",
    "   \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5PSPx85EiVn"
   },
   "outputs": [],
   "source": [
    "class Average(Layer):\n",
    "  \n",
    "    def __init__(self, mask_zero=True, **kwargs):\n",
    "        self.mask_zero = mask_zero\n",
    "        self.supports_masking = True\n",
    "        super(Average, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x,mask=None):\n",
    "        if self.mask_zero:           \n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            x = x * mask\n",
    "            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n",
    "        else:\n",
    "            return K.mean(x, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def compute_mask(self, x, mask):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GsZtx2PbEqoh"
   },
   "source": [
    "#Establish computation Grah for model\n",
    "- Input tensors\n",
    "- Shared WordEmbedding layer \n",
    "- Attention network layer  \n",
    "- Shared BiLSTM layer\n",
    "- Shared fully connected layer(prediction layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe55OCNZEmYY"
   },
   "outputs": [],
   "source": [
    "dropout = 0.5     \n",
    "recurrent_dropout = 0.1\n",
    "vocab_size = len(vocab)\n",
    "num_outputs = 3 # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2BpzACdBp3xG"
   },
   "source": [
    "##Input tensors for Aspect level model and document level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "KOi3CcOxE1MG",
    "outputId": "3afd5e97-6b55-469b-f308-0b0e3c862b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_input :  Tensor(\"sentence_input:0\", shape=(None, 82), dtype=int32)\n",
      "aspect_input   :  Tensor(\"aspect_input:0\", shape=(None, 7), dtype=int32)\n",
      "pretrain_input :  Tensor(\"pretrain_input:0\", shape=(None, None), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE ##### Inputs #####\n",
    "sentence_input = Input(shape=(overal_maxlen,), dtype='int32', name='sentence_input')  #input for sentence from aspect-level data\n",
    "aspect_input = Input(shape=(overal_maxlen_aspect,), dtype='int32', name='aspect_input') #input for aspect terms\n",
    "pretrain_input = Input(shape=(None,), dtype='int32', name='pretrain_input')             #input for sentence from document-level data\n",
    "print('sentence_input : ',  sentence_input)\n",
    "print('aspect_input   : ', aspect_input)\n",
    "print('pretrain_input : ', pretrain_input)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vQ0z8KmrL3_"
   },
   "source": [
    "##Shared WordEmbedding layer (Used for both Aspect and Document Level Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "GFEhEt9EE4Sn",
    "outputId": "2037bce3-d738-4a17-83d5-b429b68dd3dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_term_embs :  Tensor(\"word_emb/embedding_lookup/Identity_1:0\", shape=(None, 7, 300), dtype=float32)\n",
      "aspect_embs      :  Tensor(\"aspect_emb/truediv:0\", shape=(None, 300), dtype=float32)\n",
      "sentence_embs    :  Tensor(\"word_emb_1/embedding_lookup/Identity_1:0\", shape=(None, 82, 300), dtype=float32)\n",
      "pretrain_embs    :  Tensor(\"word_emb_2/embedding_lookup/Identity_1:0\", shape=(None, None, 300), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "##### create word embedding layer #####\n",
    "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n",
    "### represent aspect as averaged word embedding ###\n",
    "aspect_term_embs = word_emb(aspect_input)\n",
    "aspect_embs = Average(mask_zero=True, name='aspect_emb')(aspect_term_embs)  #There could be mutiple words for aspect terms, here is to average the wordembedding of these aspect terms\n",
    "### sentence representation ###\n",
    "sentence_embs = word_emb(sentence_input) # from aspect-level domain\n",
    "pretrain_embs = word_emb(pretrain_input) # from document-level domain\n",
    "\n",
    "print('aspect_term_embs : ', aspect_term_embs)\n",
    "print('aspect_embs      : ', aspect_embs)\n",
    "print('sentence_embs    : ', sentence_embs)\n",
    "print('pretrain_embs    : ', pretrain_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmcnAQufrc7o"
   },
   "source": [
    "##Shared BiLSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bm_yCjX_F7ml",
    "outputId": "4db6323d-0c79-418c-b84d-d56d553f24b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pretrain_bilstm :  (None, None, 600)\n",
      "Shape of sentence_bilstm :  (None, 82, 600)\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE \n",
    "rnn = Bidirectional(LSTM(300, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout), name='BiLSTM')\n",
    "### sentence representation ###\n",
    "pretrain_bilstm = rnn(pretrain_embs)    # from document-level domain\n",
    "sentence_bilstm = rnn(sentence_embs)    # from aspect-level domain\n",
    "print('Shape of pretrain_bilstm : ', pretrain_bilstm.shape)\n",
    "print('Shape of sentence_bilstm : ', sentence_bilstm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99ZNrbkmrllN"
   },
   "source": [
    "##Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HO5Pj6QANz7U",
    "outputId": "9fe173bb-00c3-40b2-cb00-860c097b19e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_weights :  Tensor(\"attention_1/truediv:0\", shape=(None, 82), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##YOUR CODE HERE\n",
    "att_weights = Attention()([sentence_bilstm, aspect_embs])\n",
    "print('att_weights : ', att_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-LY6jF8r3mO"
   },
   "source": [
    "##Shared Prediction Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxrmw-Grr6pK"
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "dotproduct = Dot(axes=1, name = \"dotproduct\")([sentence_bilstm, att_weights])\n",
    "pretrain_avg = Average(mask_zero=True)(pretrain_bilstm)\n",
    "sentence_output = Dense(num_outputs, activation='softmax', name='dense_1')(dotproduct)  #for aspect-level\n",
    "pretrain_output = Dense(num_outputs, activation='softmax', name='dense_2')(pretrain_avg)  # for document-level\n",
    "#sentence_output = Reshape((num_outputs,))(sentence_output)          # to squeeze the shape from (None,1,3) to (None,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XLv1t9Ou3vx"
   },
   "source": [
    "#Build Models for document-level and aspect-level data\n",
    "- The two models shared the embedding, BiLSTM, Prediction Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RX8qKfNWu3v0"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "model1 = Model(inputs=[pretrain_input], outputs=[pretrain_output]) #document level model\n",
    "model2 = Model(inputs=[sentence_input, aspect_input], outputs=[sentence_output]) #aspect level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "j9QFrSWtlyGX",
    "outputId": "d769b8c3-4432-4545-9530-ba47a9344163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pretrain_input (InputLayer)  (None, None)              0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         multiple                  3000900   \n",
      "_________________________________________________________________\n",
      "BiLSTM (Bidirectional)       multiple                  1442400   \n",
      "_________________________________________________________________\n",
      "average_1 (Average)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1803      \n",
      "=================================================================\n",
      "Total params: 4,445,103\n",
      "Trainable params: 4,445,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "id": "XD0V1VnflyQA",
    "outputId": "543106cd-75b4-4037-b7fc-30dc6e12885b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_input (InputLayer)     (None, 82)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aspect_input (InputLayer)       (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_emb (Embedding)            multiple             3000900     aspect_input[0][0]               \n",
      "                                                                 sentence_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "BiLSTM (Bidirectional)          multiple             1442400     word_emb[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "aspect_emb (Average)            (None, 300)          0           word_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 82)           180000      BiLSTM[1][0]                     \n",
      "                                                                 aspect_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dotproduct (Dot)                (None, 600)          0           BiLSTM[1][0]                     \n",
      "                                                                 attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            1803        dotproduct[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,625,103\n",
      "Trainable params: 4,625,103\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWqofwqBsgsn"
   },
   "source": [
    "#Train Model\n",
    "- First Train model on document-level data.\n",
    "- Then Train  model on aspect-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSLYsZm7yPwi"
   },
   "source": [
    "##Train on document-level data (model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHe86c6Yu3wG"
   },
   "outputs": [],
   "source": [
    "import keras.optimizers as opt\n",
    "optimizer=opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n",
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "batch_size = 128\n",
    "train_steps_epoch = len(pretrain_data)/batch_size\n",
    "batch_train_iter_doc = Dataiterator_doc(pretrain_data, pretrain_label, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HfEvhdbhFlbR"
   },
   "outputs": [],
   "source": [
    "###YOUR CODE HERE###\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train_generator(model, batch_train_iter):\n",
    "    \n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[X, y] for X, y in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "                \n",
    "    history1 = model.fit_generator(train_gen(), \\\n",
    "                                  steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "XH9tHIp2gYy8",
    "outputId": "e644ece9-e09c-47af-a634-c8b3f0a4c90e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/234 [==============================] - 558s 2s/step - loss: 0.9421 - categorical_accuracy: 0.5484\n",
      "Epoch 2/10\n",
      "235/234 [==============================] - 545s 2s/step - loss: 0.7962 - categorical_accuracy: 0.6376\n",
      "Epoch 3/10\n",
      "235/234 [==============================] - 538s 2s/step - loss: 0.7558 - categorical_accuracy: 0.6594\n",
      "Epoch 4/10\n",
      "235/234 [==============================] - 538s 2s/step - loss: 0.7170 - categorical_accuracy: 0.6798\n",
      "Epoch 5/10\n",
      "235/234 [==============================] - 538s 2s/step - loss: 0.6508 - categorical_accuracy: 0.7145\n",
      "Epoch 6/10\n",
      "235/234 [==============================] - 538s 2s/step - loss: 0.6725 - categorical_accuracy: 0.7093\n",
      "Epoch 7/10\n",
      "235/234 [==============================] - 536s 2s/step - loss: 0.6558 - categorical_accuracy: 0.7146\n",
      "Epoch 8/10\n",
      "235/234 [==============================] - 534s 2s/step - loss: 0.6717 - categorical_accuracy: 0.7144\n",
      "Epoch 9/10\n",
      "235/234 [==============================] - 537s 2s/step - loss: 0.5987 - categorical_accuracy: 0.7487\n",
      "Epoch 10/10\n",
      "235/234 [==============================] - 537s 2s/step - loss: 0.6274 - categorical_accuracy: 0.7316\n"
     ]
    }
   ],
   "source": [
    "train_generator(model1, batch_train_iter_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-SYaHNMyXWX"
   },
   "source": [
    "##Train on aspect-level data (model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCLGP6HTFsKL"
   },
   "outputs": [],
   "source": [
    "train_steps_epoch = len(train_x)/batch_size\n",
    "batch_train_iter_aspect = Dataiterator_aspect([train_x, train_y, train_aspect], batch_size)\n",
    "val_steps_epoch = len(dev_x)/batch_size\n",
    "batch_val_iter_aspect = Dataiterator_aspect([dev_x, dev_y, dev_aspect], batch_size)\n",
    "\n",
    "import keras.optimizers as opt\n",
    "optimizer = opt.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clipnorm=10, clipvalue=0)\n",
    "model2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kvT2GqG0LONz"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train_generator(model, batch_train_iter, batch_val_iter):\n",
    "    \n",
    "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
    "                                     monitor='val_loss', save_best_only=False, \\\n",
    "                                     save_weights_only=True)\n",
    "                     ]\n",
    "    \n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[[X, aspect], [y]] for X, y, \\\n",
    "                             aspect in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "                \n",
    "    def val_gen():\n",
    "        while True:\n",
    "            val_batches = [[[X, aspect], [y]] for X, y, \\\n",
    "                           aspect in batch_val_iter]\n",
    "            for val_batch in val_batches:\n",
    "                yield val_batch\n",
    "                \n",
    "    history2 = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
    "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 100, callbacks = earlystop_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "VZ0gdCLRgl6c",
    "outputId": "764a12c0-1035-4fc1-b06f-e5cf63beb485"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/14 [===============================] - 11s 759ms/step - loss: 1.0993 - categorical_accuracy: 0.3458 - val_loss: 1.0393 - val_categorical_accuracy: 0.5078\n",
      "Epoch 2/100\n",
      "15/14 [===============================] - 10s 695ms/step - loss: 1.0096 - categorical_accuracy: 0.5562 - val_loss: 0.9055 - val_categorical_accuracy: 0.6797\n",
      "Epoch 3/100\n",
      "15/14 [===============================] - 10s 671ms/step - loss: 0.9283 - categorical_accuracy: 0.6313 - val_loss: 0.9098 - val_categorical_accuracy: 0.6328\n",
      "Epoch 4/100\n",
      "15/14 [===============================] - 10s 666ms/step - loss: 0.9182 - categorical_accuracy: 0.5938 - val_loss: 0.7933 - val_categorical_accuracy: 0.6641\n",
      "Epoch 5/100\n",
      "15/14 [===============================] - 10s 668ms/step - loss: 0.8424 - categorical_accuracy: 0.6396 - val_loss: 0.7116 - val_categorical_accuracy: 0.6172\n",
      "Epoch 6/100\n",
      "15/14 [===============================] - 10s 676ms/step - loss: 0.8610 - categorical_accuracy: 0.6042 - val_loss: 0.8073 - val_categorical_accuracy: 0.6094\n",
      "Epoch 7/100\n",
      "15/14 [===============================] - 10s 690ms/step - loss: 0.8074 - categorical_accuracy: 0.6458 - val_loss: 0.7406 - val_categorical_accuracy: 0.6719\n",
      "Epoch 8/100\n",
      "15/14 [===============================] - 10s 679ms/step - loss: 0.8210 - categorical_accuracy: 0.6500 - val_loss: 0.7512 - val_categorical_accuracy: 0.6328\n",
      "Epoch 9/100\n",
      "15/14 [===============================] - 10s 673ms/step - loss: 0.7928 - categorical_accuracy: 0.6417 - val_loss: 0.9393 - val_categorical_accuracy: 0.5703\n",
      "Epoch 10/100\n",
      "15/14 [===============================] - 10s 688ms/step - loss: 0.7833 - categorical_accuracy: 0.6458 - val_loss: 0.8304 - val_categorical_accuracy: 0.6797\n",
      "Epoch 11/100\n",
      "15/14 [===============================] - 10s 667ms/step - loss: 0.7799 - categorical_accuracy: 0.6667 - val_loss: 0.9361 - val_categorical_accuracy: 0.6250\n",
      "Epoch 12/100\n",
      "15/14 [===============================] - 10s 691ms/step - loss: 0.8129 - categorical_accuracy: 0.6417 - val_loss: 0.6961 - val_categorical_accuracy: 0.7266\n",
      "Epoch 13/100\n",
      "15/14 [===============================] - 10s 673ms/step - loss: 0.7439 - categorical_accuracy: 0.6687 - val_loss: 0.7418 - val_categorical_accuracy: 0.6953\n",
      "Epoch 14/100\n",
      "15/14 [===============================] - 10s 691ms/step - loss: 0.7374 - categorical_accuracy: 0.6812 - val_loss: 0.9905 - val_categorical_accuracy: 0.5547\n",
      "Epoch 15/100\n",
      "15/14 [===============================] - 10s 676ms/step - loss: 0.7783 - categorical_accuracy: 0.6438 - val_loss: 0.8290 - val_categorical_accuracy: 0.7031\n",
      "Epoch 16/100\n",
      "15/14 [===============================] - 10s 679ms/step - loss: 0.7449 - categorical_accuracy: 0.6687 - val_loss: 0.8992 - val_categorical_accuracy: 0.6719\n",
      "Epoch 17/100\n",
      "15/14 [===============================] - 10s 675ms/step - loss: 0.7720 - categorical_accuracy: 0.6521 - val_loss: 1.0893 - val_categorical_accuracy: 0.5859\n",
      "Epoch 18/100\n",
      "15/14 [===============================] - 10s 693ms/step - loss: 0.7069 - categorical_accuracy: 0.6917 - val_loss: 0.7055 - val_categorical_accuracy: 0.6797\n",
      "Epoch 19/100\n",
      "15/14 [===============================] - 10s 676ms/step - loss: 0.7167 - categorical_accuracy: 0.7000 - val_loss: 0.9654 - val_categorical_accuracy: 0.5781\n",
      "Epoch 20/100\n",
      "15/14 [===============================] - 10s 672ms/step - loss: 0.6845 - categorical_accuracy: 0.7063 - val_loss: 0.8240 - val_categorical_accuracy: 0.6094\n",
      "Epoch 21/100\n",
      "15/14 [===============================] - 10s 664ms/step - loss: 0.6689 - categorical_accuracy: 0.6979 - val_loss: 0.7674 - val_categorical_accuracy: 0.7422\n",
      "Epoch 22/100\n",
      "15/14 [===============================] - 10s 672ms/step - loss: 0.7448 - categorical_accuracy: 0.6729 - val_loss: 0.9316 - val_categorical_accuracy: 0.6562\n"
     ]
    }
   ],
   "source": [
    "train_generator(model2, batch_train_iter_aspect, batch_val_iter_aspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVPNUQcuyAU3"
   },
   "source": [
    "##Evaluating on test set on model2\n",
    "- show the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J_JQwuUHMisH",
    "outputId": "f14197b4-da53-4d85-c367-e29db84c5915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "##YOUR CODE HERE\n",
    "loss, accuracy = model2.evaluate([test_x, test_aspect], test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZwuENNXYrZ6o",
    "outputId": "303b6212-7081-44c4-c8d7-12b67b13830e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  0.8247347302197663\n",
      "Accuracy :  60.501569509506226 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss : \", loss)\n",
    "print(\"Accuracy : \", (accuracy*100), \"%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Assignment-3.1.2.Aspect-Level-Sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
